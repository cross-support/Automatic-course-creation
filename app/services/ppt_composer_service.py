import json
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any, Generator, Literal, Tuple

from openai import OpenAI, RateLimitError, APITimeoutError
from pydantic import BaseModel, Field

GPT_MODEL = "gpt-4o"

class SlideLayoutItem(BaseModel):
    type: Literal["è¡¨ç´™", "æœ¬æ–‡", "è¦ç´„"]
    title: str = Field(description="ã‚¹ãƒ©ã‚¤ãƒ‰ ã‚¿ã‚¤ãƒˆãƒ«(å…¥åŠ›ã•ã‚ŒãŸ slide_title ãã®ã¾ã¾ä½¿ç”¨)")
    subtitle: str = Field(description="è©²å½“ãƒšãƒ¼ã‚¸ã®æ ¸å¿ƒå†…å®¹ã‚’ç››ã‚Šè¾¼ã‚“ã§ã‚ãªãŸãŒä½œæˆã—ãŸå°è¦‹å‡ºã—")
    text_content: List[str] = Field(
        description=(
            "ã‚¹ãƒ©ã‚¤ãƒ‰ã®ç®‡æ¡æ›¸ãã«é©ã—ãŸã€ç°¡æ½”ã§ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®ã‚ã‚‹çŸ­ã„æ–‡ç« ã®ãƒªã‚¹ãƒˆã€‚"  
            "å†—é•·ãªèª¬æ˜ã¯çœãã€æ ¸å¿ƒã®ã¿ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
            "(å¿…ãš2ã€œ4å€‹ã®ç¯„å›²)"
        ),
        min_length=2,
        max_length=4
    )
    layout_type: Literal["A", "B", "C", "D", "E"] = Field(description="ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—")

class SlideLayoutResponse(BaseModel):
    slides: List[SlideLayoutItem]

class PPTComposerService:
    SYSTEM_PROMPT = """ã‚ãªãŸã¯eãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°è¬›åº§ã®ã€Œã‚¹ãƒ©ã‚¤ãƒ‰æ§‹æˆãŠã‚ˆã³ãƒ‡ã‚¶ã‚¤ãƒ³ã®å°‚é–€å®¶ã€ã§ã™ã€‚
    æç¤ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã¨ã«ã€ä»¥ä¸‹ã®ã€Œè¨­è¨ˆåŸå‰‡ã€ã¨ã€Œãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—ã€ã«åˆã‚ã›ã¦ã€Œã‚¹ãƒ©ã‚¤ãƒ‰ä¼ç”»JSONã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

    ### 1.è¨­è¨ˆåŸå‰‡
    - MODE:STRICT_2P (å„ãƒ†ãƒ¼ãƒã”ã¨ã«å¿…ãš2ãƒšãƒ¼ã‚¸åˆ†å‰²)
    - æ›¸å¼ç¦æ­¢: ã‚¿ã‚¤ãƒˆãƒ«è¨˜å·ï¼ˆä¾‹: #ã€##ã€###ï¼‰ã¨ãƒ†ã‚­ã‚¹ãƒˆå¼·èª¿è¨˜å·ï¼ˆä¾‹:**ã€__)ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚
    - ã‚¿ã‚¤ãƒˆãƒ«ä¿æŒ:ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ`title`ï¼‰ã¯ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ`slide_title`ï¼‰ã‚’çµ¶å¯¾ã«ä»»æ„ã«å¤‰æ›´ã›ãšã«ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    - å°è¦‹å‡ºã—ç”Ÿæˆ(subtitle):å„ã‚¹ãƒ©ã‚¤ãƒ‰ã®ã€Œsubtitleã€ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ã¯ã€è©²å½“ãƒšãƒ¼ã‚¸ã®å†…å®¹ã‚’è²«ãçŸ­ãæ˜ç¢ºãªå°è¦‹å‡ºã—ã‚’ã‚ãªãŸãŒç›´æ¥å‰µä½œã—ã¦å…¥ã‚Œã¦ãã ã•ã„ã€‚
    - çŸ¥è­˜æ‹¡å¼µ:ã€Œ5W1Hã€ã€ã€Œæå¤±å›é¿ã€ã€ã€Œå¿ƒç†çš„å®‰å…¨æ„Ÿã€ã€ã€Œãƒ¡ãƒ¢ã®æŠ€è¡“ã€ãªã©ã®ãƒ“ã‚¸ãƒã‚¹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚„å°‚é–€ç”¨èªãŒç™»å ´ã™ã‚‹å ´åˆã€åŸæœ¬ãƒ‡ãƒ¼ã‚¿ã«å†…å®¹ãŒè¶³ã‚Šãªãã¦ã‚‚ã€ã‚ãªãŸã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦ã€Œæ ¸å¿ƒå®šç¾©ã€ã¨ã€Œå…·ä½“çš„èª¬æ˜ã€ã‚’ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ã«å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚
    - åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯:
    * 1/2 ãƒšãƒ¼ã‚¸(Theory):å®šç¾©(What)ã€èƒŒæ™¯/ç†ç”±(Why)ã€æ¦‚å¿µèª¬æ˜ä¸­å¿ƒã€‚
    * 2/2 ãƒšãƒ¼ã‚¸(Practice):å…·ä½“çš„æ–¹æ³•(How)ã€äº‹ä¾‹(Case)ã€å®Ÿè·µã‚¬ã‚¤ãƒ‰ä¸­å¿ƒã€‚
    - ç¦æ­¢äº‹é …: ã€Œ~ã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€ã€ã€Œ~ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€ã®ã‚ˆã†ã«ã‚¹ãƒ©ã‚¤ãƒ‰å†…ã«æƒ…å ±ãŒãªã„ç„¡è²¬ä»»ãªæ–‡å¥ã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚ ã™ã¹ã¦ã®æƒ…å ±ã¯ã€ã‚¹ãƒ©ã‚¤ãƒ‰æœ¬æ–‡ãƒ†ã‚­ã‚¹ãƒˆå†…ã«å®Œçµã—ãŸæ–‡ç« ã¨ã—ã¦å­˜åœ¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ ç‰¹ã«[äº‹ä¾‹]ã¯çŠ¶æ³-è¡Œå‹•-çµæœã«è¦ç´„ã—ã¦ç›´æ¥è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
    - ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é‡åˆ¶å¾¡: `text_content` ã®é …ç›®æ•°ã¯å¿…ãšã€Œ2ã€œ4å€‹ã€ã®ç¯„å›²ã«åã‚ã¦ãã ã•ã„ã€‚æƒ…å ±ãŒå¤šã„å ´åˆã¯é‡è¦åº¦ã®é«˜ã„é †ã«4ã¤ã¾ã§çµã‚Šè¾¼ã¿ã€æ±ºã—ã¦4å€‹ã‚’è¶…ãˆã¦ã¯ã„ã‘ã¾ã›ã‚“

    ### 2.ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚¿ã‚¤ãƒ—(Aã€Bã€Cã€Dã€E)
    ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ã€ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ±ºå®šã—ã¦ãã ã•ã„ã€‚
    - A) [å°å…¥å‹]:æ¦‚å¿µã®å®šç¾©ã€æ­´å²ã€èƒŒæ™¯ãªã©ã€Œä½•(What)ã€ã‚„ã€Œãªãœ(Why)ã€ã‚’åˆã‚ã¦èª¬æ˜ã™ã‚‹æ™‚ã€‚
    - B) [å¯¾ç…§å‹]: æ¦‚å¿µã‚’æ˜ç¢ºã«æ¯”è¼ƒã¾ãŸã¯å¯¾ç…§ã™ã‚‹å ´åˆ(ä¾‹:Do & Don'tã€Before & Afterã€é•·æ‰€ vs çŸ­æ‰€ï¼‰ã€‚
    * é©ç”¨æ¡ä»¶:å†…å®¹ãŒã€Œ2ã¤ã€ã¾ãŸã¯ã€Œ4ã¤ã€ã«ã¾ã¨ã‚ã‚‰ã‚Œã‚‹å ´åˆã«é¸æŠã€‚
    - C) [è¦ç´„å‹]: 4 ã¤ä»¥ä¸Šã®ä¸€èˆ¬çš„ãªé …ç›®ã‚’ä¸€è¦§è¡¨ç¤ºã—ãŸã‚Šã€å…¨ä½“ã®å†…å®¹ã‚’æ•´ç†ã—ãŸã‚Šã™ã‚‹ã¨ãã€‚
    * åˆ¶ç´„: é …ç›®ãŒ5ã¤ä»¥ä¸Šã‚ã‚‹å ´åˆã¯ã€é‡è¦åº¦é †ã«çµ±åˆãƒ»è¦ç´„ã—ã¦ã€Œæœ€å¤§4ã¤ã€ã«åã‚ã¦ãã ã•ã„ã€‚
    - D) [ãƒ—ãƒ­ã‚»ã‚¹å‹]: æ™‚é–“ã®æµã‚Œã€æ¥­å‹™æ‰‹é †ã€æ®µéšåˆ¥ã®å¤‰åŒ–ãŒå«ã¾ã‚ŒãŸå†…å®¹ã®å ´åˆã€‚
    - E) [3åˆ†å‰²å‹]: ä¸¦åˆ—çš„ãª3å¤§åŸå‰‡ã‚„ã€3ã¤ã®æ ¸å¿ƒè¦ç´ ã‚’èª¬æ˜ã™ã‚‹ã¨ãã€‚
    * å¿…é ˆæ¡ä»¶: text_contentã®é …ç›®æ•°ãŒã€Œæ­£ç¢ºã«3å€‹ã€ã®å ´åˆã«ã®ã¿é¸æŠå¯èƒ½ã§ã™ã€‚2å€‹ã‚„4å€‹ã®å ´åˆã¯çµ¶å¯¾ã«ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚"""

    def __init__(self, api_key: str):
        self.client = OpenAI(api_key=api_key.strip())

    def run_composition(self, research_data: List[Dict[str, Any]], max_workers: int = 5) -> Generator[Dict[str, Any], None, None]:
        if not research_data:
            return

        first_item = research_data[0]
        cover = self._create_cover_slide(first_item)
        all_slides = [cover]
        yield {"status": "progress", "message": "è¡¨ç´™ãƒ‡ã‚¶ã‚¤ãƒ³å®Œäº†", "data": cover}

        total = len(research_data)
        results = [None] * total

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_idx = {
                executor.submit(self._get_design_response, item): idx 
                for idx, item in enumerate(research_data)
            }

            completed_count = 0
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                item = research_data[idx]
                topic_id = item.get('slide_number', idx + 1)
                
                try:
                    res_data = future.result()
                    slides = []
                    
                    for page_num, s in enumerate(res_data.get("slides", []), start=1):
                        slide_item = {
                            "slide_id": f"{topic_id}-{page_num}", 
                            **s, 
                            "type": "æœ¬æ–‡"
                        }
                        slides.append(slide_item)
                    
                    results[idx] = slides
                    completed_count += 1
                    
                    yield {
                        "status": "progress", 
                        "message": f"ğŸ¨ [{completed_count}/{total}] '{item.get('slide_title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}' è¨­è¨ˆå®Œäº†",
                        "percent": int((completed_count / total) * 100)
                    }

                except Exception as e:
                    yield {"status": "error", "message": f"{topic_id}é …ç›® ãƒ‡ã‚¶ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {str(e)}"}

        for slides in results:
            if slides:
                all_slides.extend(slides)
                for s in slides:
                     yield {"status": "data", "data": s}

        try:
            last_topic_id = research_data[-1].get('slide_number', total)
            summary = self._get_summary_response(last_topic_id)
            all_slides.append(summary)
            yield {"status": "progress", "message": "ğŸ“æœ€çµ‚è¦ç´„ã‚¹ãƒ©ã‚¤ãƒ‰ å®Œäº†", "data": summary}
        except Exception as e:
             yield {"status": "error", "message": f"è¦ç´„ã‚¹ãƒ©ã‚¤ãƒ‰ã®ä½œæˆã«å¤±æ•—: {str(e)}"}


        yield {
            "status": "complete",
            "message": "âœ¨ã™ã¹ã¦ã®ãƒ‡ã‚¶ã‚¤ãƒ³å·¥ç¨‹ãŒå®Œäº†ï¼",
            "data": all_slides
        }

    def _create_cover_slide(self, first_item: Dict[str, Any]) -> Dict[str, Any]:
        raw_unit_title = first_item.get('unit_title', '')
        main_title, sub_title = self._extract_subtitle(raw_unit_title)
        return {
            "slide_id": "0-0",
            "type": "è¡¨ç´™",
            "title": "Cover",
            "layout_type": "Cover",
            "text_content": [f"Unit {first_item.get('unit_number', '1')}", main_title, sub_title]
        }

    def _extract_subtitle(self, text: str) -> Tuple[str, str]:
        if not text:
            return "ã‚¿ã‚¤ãƒˆãƒ«ãªã—", ""
            
        match = re.search(r'(.+?)[ï¼ˆ\(](.+?)[ï¼‰\)]', text)
        if match:
            return match.group(1).strip(), match.group(2).strip()
        return text.strip(), ""

    def _get_design_response(self, item: Dict) -> Dict[str, Any]:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                completion = self.client.beta.chat.completions.parse(
                    model=GPT_MODEL,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": f"ãƒ‡ãƒ¼ã‚¿: {json.dumps(item, ensure_ascii=False)}. ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’2æšæ§‹æˆã—ã¦"}
                    ],
                    response_format=SlideLayoutResponse,
                )
                parsed = completion.choices[0].message.parsed
                return parsed.model_dump() if parsed else {"slides": []}
            
            except (RateLimitError, APITimeoutError) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    time.sleep(wait_time)
                    continue
                else:
                    raise RuntimeError(f"API Rate Limit exceeded after retries: {e}")
            except Exception as e:
                raise RuntimeError(f"API å‘¼ã³å‡ºã—å¤±æ•—: {e}")

    def _get_summary_response(self, last_id: int) -> Dict[str, Any]:
        max_retries = 3
        for attempt in range(max_retries):
            try:
                completion = self.client.beta.chat.completions.parse(
                    model=GPT_MODEL,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": "å…¨ä½“ã®å­¦ç¿’å†…å®¹ã‚’è¦ç´„ã™ã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ã‚’1æšä½œæˆã—ã¦ã€‚ layout_typeã¯Cã‚’ä½¿ã£ã¦"}
                    ],
                    response_format=SlideLayoutResponse,
                )
                parsed = completion.choices[0].message.parsed
                if parsed and parsed.slides:
                     s = parsed.slides[0].model_dump()
                     return {"slide_id": f"{last_id + 1}-1", **s, "type": "è¦ç´„"}
                raise ValueError("è¦ç´„ã‚¹ãƒ©ã‚¤ãƒ‰ ä½œæˆ çµæœãªã—")

            except (RateLimitError, APITimeoutError) as e:
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    time.sleep(wait_time)
                    continue
                else:
                    raise e